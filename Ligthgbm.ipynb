{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mibassan/master/blob/master/Ligthgbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f70472-e7c5-4172-a8c8-85609c087247",
      "metadata": {
        "id": "92f70472-e7c5-4172-a8c8-85609c087247"
      },
      "outputs": [],
      "source": [
        "#import pandas as pd\n",
        "\n",
        "# Lee el archivo como un DataFrame\n",
        "#df_ventas = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/sell-in.txt', delimiter='\\t',  decimal='.')  # Cambia el delimitador si es necesario\n",
        "#df_predict = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/productos_a_predecir.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
        "#df_product = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/tb_productoscorregida.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
        "#df_stocks = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/tb_stocks.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzXOInmNGsoR",
        "outputId": "2b523a6d-eb97-4cb3-a571-14d995174496"
      },
      "id": "YzXOInmNGsoR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Leer el archivo CSV con pandas\n",
        "df_ventas = pd.read_csv('/content/drive/My Drive/Labo3/sell-in.txt', delimiter='\\t',  decimal='.')  # Cambia el delimitador si es necesario\n",
        "df_predict = pd.read_csv('/content/drive/My Drive/Labo3/productos_a_predecir.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
        "df_product = pd.read_csv('/content/drive/My Drive/Labo3/tb_productoscorregida.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
        "df_stocks = pd.read_csv('/content/drive/My Drive/Labo3/tb_stocks.txt', delimiter='\\t')  # Cambia el delimitador si es necesario"
      ],
      "metadata": {
        "id": "6GY7G7zPHrud"
      },
      "id": "6GY7G7zPHrud",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b8373aa3-3e24-4d3d-8968-ec320ffdc46e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b8373aa3-3e24-4d3d-8968-ec320ffdc46e",
        "outputId": "5c50fd14-2e1d-420e-fd35-53b19ae466ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
            "0   201701        10234       20524                      0                 2   \n",
            "1   201701        10032       20524                      0                 1   \n",
            "2   201701        10217       20524                      0                 1   \n",
            "3   201701        10125       20524                      0                 1   \n",
            "4   201701        10012       20524                      0                11   \n",
            "\n",
            "   cust_request_tn       tn  \n",
            "0          0.05300  0.05300  \n",
            "1          0.13628  0.13628  \n",
            "2          0.03028  0.03028  \n",
            "3          0.02271  0.02271  \n",
            "4          1.54452  1.54452  \n",
            "   periodo  product_id  stock_final\n",
            "0   201810       20524      1.61267\n",
            "1   201810       20311      2.93657\n",
            "2   201810       20654      6.83269\n",
            "3   201810       21005      1.01338\n",
            "4   201810       20974      0.34595\n",
            "  cat1         cat2     cat3    brand  sku_size  product_id\n",
            "0   HC  ROPA LAVADO  Liquido  LIMPIEX       900       20280\n",
            "1   HC  ROPA LAVADO  Liquido  LIMPIEX       450       20180\n",
            "2   HC  ROPA LAVADO  Liquido  LIMPIEX       120       20332\n",
            "3   HC  ROPA LAVADO  Liquido  LIMPIEX       450       20222\n",
            "4   HC  ROPA LAVADO  Liquido  LIMPIEX       900       20288\n"
          ]
        }
      ],
      "source": [
        "print(df_ventas.head())\n",
        "print(df_stocks.head())\n",
        "print(df_product.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7f8f5b40-66cb-4cb3-bb2e-f80bc5ebd5a2",
      "metadata": {
        "id": "7f8f5b40-66cb-4cb3-bb2e-f80bc5ebd5a2"
      },
      "outputs": [],
      "source": [
        "df_ventas.periodo = pd.to_datetime(df_ventas.periodo, format='%Y%m')\n",
        "# Convertir 'periodo' a formato de fecha\n",
        "#data['periodo'] = pd.to_datetime(data['periodo'], format='%Y%m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "031de60c-6300-49ce-8313-12a7d88f0db7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "031de60c-6300-49ce-8313-12a7d88f0db7",
        "outputId": "ec60c1af-7eee-4005-8f7f-e0704f43e4fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
              "0 2017-01-01        10234       20524                      0   \n",
              "1 2017-01-01        10032       20524                      0   \n",
              "2 2017-01-01        10217       20524                      0   \n",
              "3 2017-01-01        10125       20524                      0   \n",
              "4 2017-01-01        10012       20524                      0   \n",
              "\n",
              "   cust_request_qty  cust_request_tn       tn  \n",
              "0                 2          0.05300  0.05300  \n",
              "1                 1          0.13628  0.13628  \n",
              "2                 1          0.03028  0.03028  \n",
              "3                 1          0.02271  0.02271  \n",
              "4                11          1.54452  1.54452  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1708b935-37e6-4e02-95a0-bc10e1d20ec7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>periodo</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>plan_precios_cuidados</th>\n",
              "      <th>cust_request_qty</th>\n",
              "      <th>cust_request_tn</th>\n",
              "      <th>tn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10234</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.05300</td>\n",
              "      <td>0.05300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10032</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13628</td>\n",
              "      <td>0.13628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10217</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03028</td>\n",
              "      <td>0.03028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10125</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02271</td>\n",
              "      <td>0.02271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10012</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.54452</td>\n",
              "      <td>1.54452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1708b935-37e6-4e02-95a0-bc10e1d20ec7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1708b935-37e6-4e02-95a0-bc10e1d20ec7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1708b935-37e6-4e02-95a0-bc10e1d20ec7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8545a8c2-43d7-4f4c-b0ce-08e69b489c38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8545a8c2-43d7-4f4c-b0ce-08e69b489c38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8545a8c2-43d7-4f4c-b0ce-08e69b489c38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_ventas"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_ventas.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Armado del dataset para los productos a predecir"
      ],
      "metadata": {
        "id": "AMCiAaIWNdmf"
      },
      "id": "AMCiAaIWNdmf"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8f627665-bb59-455a-859b-c04b65a68a09",
      "metadata": {
        "id": "8f627665-bb59-455a-859b-c04b65a68a09"
      },
      "outputs": [],
      "source": [
        "# Armado de la lista de productos validos a predecir para el periodo\n",
        "product_ids_validos = df_predict['product_id'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9da04535-3490-49f0-b28b-dbdc8ef06f96",
      "metadata": {
        "id": "9da04535-3490-49f0-b28b-dbdc8ef06f96"
      },
      "outputs": [],
      "source": [
        "# Filtrar el DataFrame original para quedarse solo con los product_id válidos\n",
        "# En un nuevo Data Frame llamado \"DATA\"\n",
        "data = df_ventas[df_ventas['product_id'].isin(product_ids_validos)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a3f1d96b-1c62-4d32-8ea0-81880e95abeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "collapsed": true,
        "id": "a3f1d96b-1c62-4d32-8ea0-81880e95abeb",
        "outputId": "7c92f3c5-c5ae-462a-c0c3-e9d4a141116d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   product_id    periodo  cust_request_qty  customer_id  tn  tn_lag_1  \\\n",
              "0       20001 2017-01-01                 1      10014.0   0       0.0   \n",
              "1       20001 2017-01-01                 1      10018.0   1       0.0   \n",
              "2       20001 2017-01-01                 1      10024.0   0       1.0   \n",
              "3       20001 2017-01-01                 1      10042.0   0       0.0   \n",
              "4       20001 2017-01-01                 1      10043.0   0       0.0   \n",
              "\n",
              "   tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_12  year  month  \n",
              "0       0.0       0.0       0.0        0.0  2017      1  \n",
              "1       0.0       0.0       0.0        0.0  2017      1  \n",
              "2       0.0       0.0       0.0        0.0  2017      1  \n",
              "3       1.0       0.0       0.0        0.0  2017      1  \n",
              "4       0.0       1.0       0.0        0.0  2017      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd75b6ae-e448-4582-8666-6a979602343f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>periodo</th>\n",
              "      <th>cust_request_qty</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>tn</th>\n",
              "      <th>tn_lag_1</th>\n",
              "      <th>tn_lag_2</th>\n",
              "      <th>tn_lag_3</th>\n",
              "      <th>tn_lag_6</th>\n",
              "      <th>tn_lag_12</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>10014.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>10018.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>10024.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>10042.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>10043.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd75b6ae-e448-4582-8666-6a979602343f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd75b6ae-e448-4582-8666-6a979602343f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd75b6ae-e448-4582-8666-6a979602343f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-50426565-c806-4546-8708-86ba3404cc85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50426565-c806-4546-8708-86ba3404cc85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-50426565-c806-4546-8708-86ba3404cc85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7c4574e0-b363-4382-86d8-8d80e74f865e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7c4574e0-b363-4382-86d8-8d80e74f865e",
        "outputId": "cf336074-103f-4f8b-af12-e497acb8b1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2293481 entries, 0 to 2945817\n",
            "Data columns (total 7 columns):\n",
            " #   Column                 Dtype         \n",
            "---  ------                 -----         \n",
            " 0   periodo                datetime64[ns]\n",
            " 1   customer_id            int64         \n",
            " 2   product_id             int64         \n",
            " 3   plan_precios_cuidados  int64         \n",
            " 4   cust_request_qty       int64         \n",
            " 5   cust_request_tn        float64       \n",
            " 6   tn                     float64       \n",
            "dtypes: datetime64[ns](1), float64(2), int64(4)\n",
            "memory usage: 140.0 MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ed031c9e-1642-4296-90bc-fad03b98512e",
      "metadata": {
        "id": "ed031c9e-1642-4296-90bc-fad03b98512e"
      },
      "outputs": [],
      "source": [
        "# Función para agregar los valores de 'tn' por 'product_id' y 'periodo'\n",
        "\n",
        "# Definir la función aggregate_data\n",
        "def aggregate_data(df_ventas):\n",
        "    return df_ventas.groupby(['product_id', 'periodo','cust_request_qty'])['tn'].sum().reset_index()\n",
        "\n",
        "# Agrupar los datos\n",
        "data = aggregate_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5b16f3e4-098a-44ec-9e3c-0f3ab5426b5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "5b16f3e4-098a-44ec-9e3c-0f3ab5426b5d",
        "outputId": "e2b8f04e-cbf9-4a46-8c8b-d07b8b322ba6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   product_id    periodo  cust_request_qty        tn\n",
              "0       20001 2017-01-01                 1  71.89266\n",
              "1       20001 2017-01-01                 2  50.26777\n",
              "2       20001 2017-01-01                 3  73.13506\n",
              "3       20001 2017-01-01                 4  24.64697\n",
              "4       20001 2017-01-01                 5  14.97624"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c6c548b-2e4d-4c8d-b0d3-1fd65a679708\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>periodo</th>\n",
              "      <th>cust_request_qty</th>\n",
              "      <th>tn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>71.89266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>50.26777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>3</td>\n",
              "      <td>73.13506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>4</td>\n",
              "      <td>24.64697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20001</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>5</td>\n",
              "      <td>14.97624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c6c548b-2e4d-4c8d-b0d3-1fd65a679708')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c6c548b-2e4d-4c8d-b0d3-1fd65a679708 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c6c548b-2e4d-4c8d-b0d3-1fd65a679708');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-49e9f998-423a-498b-9a13-25f0076f5a4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49e9f998-423a-498b-9a13-25f0076f5a4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-49e9f998-423a-498b-9a13-25f0076f5a4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e0b183b4-2a66-44e6-9e1d-ca493f0da1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e0b183b4-2a66-44e6-9e1d-ca493f0da1f7",
        "outputId": "0b01e7f9-99ad-476e-d6d4-27a4dc9b7480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         product_id    periodo  customer_id  plan_precios_cuidados  \\\n",
            "0             20001 2017-01-01      10001.0                    0.0   \n",
            "1             20001 2017-01-01      10063.0                    0.0   \n",
            "2             20001 2017-01-01      10080.0                    0.0   \n",
            "3             20001 2017-01-01      10094.0                    0.0   \n",
            "4             20001 2017-01-01      10184.0                    0.0   \n",
            "...             ...        ...          ...                    ...   \n",
            "2299207       21276 2019-11-01      10154.0                    0.0   \n",
            "2299208       21276 2019-12-01      10219.0                    0.0   \n",
            "2299209       21276 2019-12-01      10052.0                    0.0   \n",
            "2299210       21276 2019-12-01      10029.0                    0.0   \n",
            "2299211       21276 2019-12-01      10289.0                    0.0   \n",
            "\n",
            "         cust_request_qty  cust_request_tn        tn  \n",
            "0                    11.0         99.43861  99.43861  \n",
            "1                     1.0          0.12312   0.12312  \n",
            "2                     1.0          0.24625   0.24625  \n",
            "3                     1.0          1.23123   1.23123  \n",
            "4                     1.0          0.06716   0.06716  \n",
            "...                   ...              ...       ...  \n",
            "2299207               1.0          0.00148   0.00148  \n",
            "2299208               1.0          0.00075   0.00075  \n",
            "2299209               1.0          0.00594   0.00594  \n",
            "2299210               1.0          0.00075   0.00075  \n",
            "2299211               1.0          0.00148   0.00148  \n",
            "\n",
            "[2299212 rows x 7 columns]\n",
            "\n",
            "DataFrame con todos los product_id en todos los periodos:\n",
            "         product_id    periodo  customer_id  plan_precios_cuidados  \\\n",
            "0             20001 2017-01-01      10001.0                    0.0   \n",
            "1             20001 2017-01-01      10063.0                    0.0   \n",
            "2             20001 2017-01-01      10080.0                    0.0   \n",
            "3             20001 2017-01-01      10094.0                    0.0   \n",
            "4             20001 2017-01-01      10184.0                    0.0   \n",
            "...             ...        ...          ...                    ...   \n",
            "2299207       21276 2019-11-01      10154.0                    0.0   \n",
            "2299208       21276 2019-12-01      10219.0                    0.0   \n",
            "2299209       21276 2019-12-01      10052.0                    0.0   \n",
            "2299210       21276 2019-12-01      10029.0                    0.0   \n",
            "2299211       21276 2019-12-01      10289.0                    0.0   \n",
            "\n",
            "         cust_request_qty  cust_request_tn  tn  \n",
            "0                      11         99.43861  99  \n",
            "1                       1          0.12312   0  \n",
            "2                       1          0.24625   0  \n",
            "3                       1          1.23123   1  \n",
            "4                       1          0.06716   0  \n",
            "...                   ...              ...  ..  \n",
            "2299207                 1          0.00148   0  \n",
            "2299208                 1          0.00075   0  \n",
            "2299209                 1          0.00594   0  \n",
            "2299210                 1          0.00075   0  \n",
            "2299211                 1          0.00148   0  \n",
            "\n",
            "[2299212 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Obtener todos los productos y periodos únicos\n",
        "all_product_ids = data['product_id'].unique()\n",
        "all_periods = data['periodo'].unique()\n",
        "\n",
        "# Crear un DataFrame con todas las combinaciones posibles de product_id y periodo\n",
        "all_combinations = pd.MultiIndex.from_product([all_product_ids, all_periods], names=['product_id', 'periodo']).to_frame(index=False)\n",
        "\n",
        "# Realizar el merge con el DataFrame original, llenando los valores faltantes con 0\n",
        "df_complete = pd.merge(all_combinations, df_ventas, on=['product_id', 'periodo'], how='left').fillna(0)\n",
        "\n",
        "# Verificar el resultado\n",
        "print(df_complete)\n",
        "\n",
        "# Asegurarse de que los tipos de datos sean correctos\n",
        "df_complete['cust_request_qty'] = df_complete['cust_request_qty'].astype(int)\n",
        "df_complete['tn'] = df_complete['tn'].astype(int)\n",
        "\n",
        "# Mostrar el DataFrame completo\n",
        "print(\"\\nDataFrame con todos los product_id en todos los periodos:\")\n",
        "print(df_complete)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "644767d7-32e8-438f-8521-af35d2027aa0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644767d7-32e8-438f-8521-af35d2027aa0",
        "outputId": "db19e071-4111-42c6-ff34-08dfdd2f8c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de valores únicos en 'product_id': 780\n"
          ]
        }
      ],
      "source": [
        "# Contar la cantidad de valores únicos en la columna 'product_id'\n",
        "unique_product_ids = df_complete['product_id'].nunique()\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"Cantidad de valores únicos en 'product_id':\", unique_product_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b2008d08-5462-4770-8518-917f2dba52e7",
      "metadata": {
        "id": "b2008d08-5462-4770-8518-917f2dba52e7"
      },
      "outputs": [],
      "source": [
        "# Función para agregar los valores de 'tn' por 'product_id' y 'periodo'\n",
        "\n",
        "# Definir la función aggregate_data\n",
        "def aggregate_data(df_complete):\n",
        "    return df_complete.groupby(['product_id', 'periodo','cust_request_qty','customer_id'])['tn'].sum().reset_index()\n",
        "\n",
        "# Agrupar los datos\n",
        "data2 = aggregate_data(df_complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9a5f05d0-8161-403c-9d76-9372006f2e9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9a5f05d0-8161-403c-9d76-9372006f2e9a",
        "outputId": "19f1c9b5-0e94-4436-d82a-4d3a4d026550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         product_id    periodo  cust_request_qty  customer_id  tn\n",
            "0             20001 2017-01-01                 1      10014.0   0\n",
            "1             20001 2017-01-01                 1      10018.0   1\n",
            "2             20001 2017-01-01                 1      10024.0   0\n",
            "3             20001 2017-01-01                 1      10042.0   0\n",
            "4             20001 2017-01-01                 1      10043.0   0\n",
            "...             ...        ...               ...          ...  ..\n",
            "2299207       21276 2019-11-01                 2      10550.0   0\n",
            "2299208       21276 2019-12-01                 1      10029.0   0\n",
            "2299209       21276 2019-12-01                 1      10052.0   0\n",
            "2299210       21276 2019-12-01                 1      10219.0   0\n",
            "2299211       21276 2019-12-01                 1      10289.0   0\n",
            "\n",
            "[2299212 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "print(data2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calulamos **LAGs**"
      ],
      "metadata": {
        "id": "_Pc3ruQcnWt7"
      },
      "id": "_Pc3ruQcnWt7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar lags para la característica 'tn' (variable objetivo)\n",
        "lags = [1, 2, 3, 6, 12]  # Lags de 1 mes, 2 meses y 3 m\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos de data\n",
        "for lag in lags:\n",
        "    data2[f'tn_lag_{lag}'] = data2.groupby('product_id')['tn'].shift(lag)\n",
        "# Reemplazar NaN por 0 en las columnas de lags\n",
        "lag_columns = [f'tn_lag_{lag}' for lag in lags]\n",
        "data2[lag_columns] = data2[lag_columns].fillna(0)\n"
      ],
      "metadata": {
        "id": "EeRAxL-7b6Cg"
      },
      "id": "EeRAxL-7b6Cg",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tvwN5XCLcSRS",
        "outputId": "e6c48412-5e14-478b-d8de-f9b42a946fde"
      },
      "id": "tvwN5XCLcSRS",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         product_id    periodo  cust_request_qty  customer_id  tn  tn_lag_1  \\\n",
            "0             20001 2017-01-01                 1      10014.0   0       0.0   \n",
            "1             20001 2017-01-01                 1      10018.0   1       0.0   \n",
            "2             20001 2017-01-01                 1      10024.0   0       1.0   \n",
            "3             20001 2017-01-01                 1      10042.0   0       0.0   \n",
            "4             20001 2017-01-01                 1      10043.0   0       0.0   \n",
            "...             ...        ...               ...          ...  ..       ...   \n",
            "2299207       21276 2019-11-01                 2      10550.0   0       0.0   \n",
            "2299208       21276 2019-12-01                 1      10029.0   0       0.0   \n",
            "2299209       21276 2019-12-01                 1      10052.0   0       0.0   \n",
            "2299210       21276 2019-12-01                 1      10219.0   0       0.0   \n",
            "2299211       21276 2019-12-01                 1      10289.0   0       0.0   \n",
            "\n",
            "         tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_12  \n",
            "0             0.0       0.0       0.0        0.0  \n",
            "1             0.0       0.0       0.0        0.0  \n",
            "2             0.0       0.0       0.0        0.0  \n",
            "3             1.0       0.0       0.0        0.0  \n",
            "4             0.0       1.0       0.0        0.0  \n",
            "...           ...       ...       ...        ...  \n",
            "2299207       0.0       0.0       0.0        0.0  \n",
            "2299208       0.0       0.0       0.0        0.0  \n",
            "2299209       0.0       0.0       0.0        0.0  \n",
            "2299210       0.0       0.0       0.0        0.0  \n",
            "2299211       0.0       0.0       0.0        0.0  \n",
            "\n",
            "[2299212 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data2\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5OTzOEbkc-5T",
        "outputId": "77ccdbd9-ca79-4100-d8ab-656cf7a78309"
      },
      "id": "5OTzOEbkc-5T",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         product_id    periodo  cust_request_qty  customer_id  tn  tn_lag_1  \\\n",
            "0             20001 2017-01-01                 1      10014.0   0       0.0   \n",
            "1             20001 2017-01-01                 1      10018.0   1       0.0   \n",
            "2             20001 2017-01-01                 1      10024.0   0       1.0   \n",
            "3             20001 2017-01-01                 1      10042.0   0       0.0   \n",
            "4             20001 2017-01-01                 1      10043.0   0       0.0   \n",
            "...             ...        ...               ...          ...  ..       ...   \n",
            "2299207       21276 2019-11-01                 2      10550.0   0       0.0   \n",
            "2299208       21276 2019-12-01                 1      10029.0   0       0.0   \n",
            "2299209       21276 2019-12-01                 1      10052.0   0       0.0   \n",
            "2299210       21276 2019-12-01                 1      10219.0   0       0.0   \n",
            "2299211       21276 2019-12-01                 1      10289.0   0       0.0   \n",
            "\n",
            "         tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_12  \n",
            "0             0.0       0.0       0.0        0.0  \n",
            "1             0.0       0.0       0.0        0.0  \n",
            "2             0.0       0.0       0.0        0.0  \n",
            "3             1.0       0.0       0.0        0.0  \n",
            "4             0.0       1.0       0.0        0.0  \n",
            "...           ...       ...       ...        ...  \n",
            "2299207       0.0       0.0       0.0        0.0  \n",
            "2299208       0.0       0.0       0.0        0.0  \n",
            "2299209       0.0       0.0       0.0        0.0  \n",
            "2299210       0.0       0.0       0.0        0.0  \n",
            "2299211       0.0       0.0       0.0        0.0  \n",
            "\n",
            "[2299212 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM **Primer Version**"
      ],
      "metadata": {
        "id": "yaoITjk0nIA5"
      },
      "id": "yaoITjk0nIA5"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = data2\n",
        "\n",
        "# Crear características adicionales (features)\n",
        "data['year'] = data['periodo'].dt.year\n",
        "data['month'] = data['periodo'].dt.month\n",
        "\n",
        "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
        "train_data = data[data['periodo'] <= '2019-12-01']\n",
        "\n",
        "# Definir las características y el target\n",
        "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty']\n",
        "target = 'tn'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar el modelo LightGBM\n",
        "model = LGBMRegressor()\n",
        "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "\n",
        "# Crear el DataFrame para las predicciones de febrero de 2020\n",
        "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset\n",
        "unique_product_ids = data['product_id'].unique()\n",
        "unique_customer_ids = data['customer_id'].unique()\n",
        "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
        "\n",
        "# Añadir las columnas necesarias\n",
        "prediction_data['year'] = 2020\n",
        "prediction_data['month'] = 2\n",
        "\n",
        "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
        "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
        "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
        "\n",
        "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
        "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
        "\n",
        "# Asignar valores de 'tn'\n",
        "prediction_data['tn'] = data['tn']\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
        "lags = [1, 2, 3, 6, 12]\n",
        "for lag in lags:\n",
        "    prediction_data[f'tn_lag_{lag}'] = prediction_data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Hacer predicciones\n",
        "X_pred = prediction_data[features]\n",
        "prediction_data['tn'] = model.predict(X_pred)\n",
        "\n",
        "# Agrupar por product_id y sumar las predicciones de tn\n",
        "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
        "\n",
        "# Añadir la columna de periodo\n",
        "grouped_predictions['periodo'] = '202002'\n",
        "\n",
        "# Seleccionar columnas y guardar en CSV\n",
        "output = grouped_predictions[['product_id', 'tn']]\n",
        "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
        "\n",
        "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I5iPMJqiCF9",
        "outputId": "0beee5ac-6ac7-4fc7-989f-c94e9339bdfb"
      },
      "id": "4I5iPMJqiCF9",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031235 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 589\n",
            "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 0.352071\n",
            "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AWM-q9M5gs02",
        "outputId": "635d9a30-8200-4c55-a86d-b31c7e83e1da"
      },
      "id": "AWM-q9M5gs02",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         product_id    periodo  cust_request_qty  customer_id  tn  year  \\\n",
            "0             20001 2017-01-01                 1      10014.0   0  2017   \n",
            "1             20001 2017-01-01                 1      10018.0   1  2017   \n",
            "2             20001 2017-01-01                 1      10024.0   0  2017   \n",
            "3             20001 2017-01-01                 1      10042.0   0  2017   \n",
            "4             20001 2017-01-01                 1      10043.0   0  2017   \n",
            "...             ...        ...               ...          ...  ..   ...   \n",
            "2299207       21276 2019-11-01                 2      10550.0   0  2019   \n",
            "2299208       21276 2019-12-01                 1      10029.0   0  2019   \n",
            "2299209       21276 2019-12-01                 1      10052.0   0  2019   \n",
            "2299210       21276 2019-12-01                 1      10219.0   0  2019   \n",
            "2299211       21276 2019-12-01                 1      10289.0   0  2019   \n",
            "\n",
            "         month  tn_lag_1  tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_12  \n",
            "0            1       0.0       0.0       0.0       0.0        0.0  \n",
            "1            1       0.0       0.0       0.0       0.0        0.0  \n",
            "2            1       1.0       0.0       0.0       0.0        0.0  \n",
            "3            1       0.0       1.0       0.0       0.0        0.0  \n",
            "4            1       0.0       0.0       1.0       0.0        0.0  \n",
            "...        ...       ...       ...       ...       ...        ...  \n",
            "2299207     11       0.0       0.0       0.0       0.0        0.0  \n",
            "2299208     12       0.0       0.0       0.0       0.0        0.0  \n",
            "2299209     12       0.0       0.0       0.0       0.0        0.0  \n",
            "2299210     12       0.0       0.0       0.0       0.0        0.0  \n",
            "2299211     12       0.0       0.0       0.0       0.0        0.0  \n",
            "\n",
            "[2299212 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM CON **LAGS**"
      ],
      "metadata": {
        "id": "yAxRWg9xnA9q"
      },
      "id": "yAxRWg9xnA9q"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = data2\n",
        "\n",
        "# Crear características adicionales (features)\n",
        "data['year'] = data['periodo'].dt.year\n",
        "data['month'] = data['periodo'].dt.month\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos\n",
        "lags = [1, 2, 3, 6, 12]\n",
        "for lag in lags:\n",
        "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
        "train_data = data[data['periodo'] <= '2019-12-01']\n",
        "\n",
        "# Definir las características y el target\n",
        "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
        "target = 'tn'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar el modelo LightGBM\n",
        "model = LGBMRegressor()\n",
        "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "\n",
        "# Crear el DataFrame para las predicciones de febrero de 2020\n",
        "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset original\n",
        "unique_product_ids = data2['product_id'].unique()\n",
        "unique_customer_ids = data2['customer_id'].unique()\n",
        "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
        "# Añadir las columnas necesarias para las características adicionales\n",
        "prediction_data['year'] = 2020\n",
        "prediction_data['month'] = 2\n",
        "# Agregar la columna 'tn' al DataFrame de predicciones\n",
        "prediction_data['tn'] = np.nan  # Creamos la columna con NaN\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
        "for lag in lags:\n",
        "    prediction_data[f'tn_lag_{lag}'] = prediction_data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
        "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
        "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
        "\n",
        "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
        "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
        "\n",
        "# Hacer predicciones\n",
        "X_pred = prediction_data[features]\n",
        "prediction_data['tn'] = model.predict(X_pred)\n",
        "\n",
        "# Agrupar por product_id y sumar las predicciones de tn\n",
        "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
        "\n",
        "# Añadir la columna de periodo\n",
        "grouped_predictions['periodo'] = '202002'\n",
        "\n",
        "# Seleccionar columnas y guardar en CSV\n",
        "output = grouped_predictions[['product_id', 'tn']]\n",
        "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
        "\n",
        "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI-vEmjUYOJQ",
        "outputId": "650dd68d-1639-41c8-b40c-7ff8ed6a299a"
      },
      "id": "hI-vEmjUYOJQ",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130672 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1005\n",
            "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352071\n",
            "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = data2\n",
        "\n",
        "# Crear características adicionales (features)\n",
        "data['year'] = data['periodo'].dt.year\n",
        "data['month'] = data['periodo'].dt.month\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos\n",
        "lags = [1, 2, 3, 6, 12]\n",
        "for lag in lags:\n",
        "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
        "train_data = data[data['periodo'] <= '2019-12-01']\n",
        "\n",
        "# Definir las características y el target\n",
        "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
        "target = 'tn'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Reemplazar valores faltantes con 0\n",
        "X.fillna(0, inplace=True)\n",
        "y.fillna(0, inplace=True)\n",
        "\n",
        "# Entrenar un modelo de regresión lineal para cada product_id\n",
        "product_ids = data['product_id'].unique()\n",
        "regressions = {}\n",
        "for pid in product_ids:\n",
        "    X_pid = X[X['product_id'] == pid]\n",
        "    y_pid = y[X['product_id'] == pid]\n",
        "    regression = LinearRegression()\n",
        "    regression.fit(X_pid, y_pid)\n",
        "    regressions[pid] = regression\n",
        "\n",
        "# Crear el DataFrame para las predicciones de febrero de 2020\n",
        "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset original\n",
        "unique_product_ids = data2['product_id'].unique()\n",
        "unique_customer_ids = data2['customer_id'].unique()\n",
        "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
        "# Añadir las columnas necesarias para las características adicionales\n",
        "prediction_data['year'] = 2020\n",
        "prediction_data['month'] = 2\n",
        "# Agregar la columna 'tn' al DataFrame de predicciones\n",
        "prediction_data['tn'] = np.nan  # Creamos la columna con NaN\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
        "for lag in lags:\n",
        "    prediction_data[f'tn_lag_{lag}'] = prediction_data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
        "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
        "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
        "\n",
        "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
        "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
        "\n",
        "# Reemplazar valores faltantes con 0\n",
        "prediction_data.fillna(0, inplace=True)\n",
        "\n",
        "# Predicciones usando regresión lineal para cada product_id\n",
        "for pid, regression in regressions.items():\n",
        "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
        "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] = regression.predict(X_pid_pred)\n",
        "\n",
        "# Hacer predicciones finales usando LightGBM\n",
        "X_pred = prediction_data[features]\n",
        "prediction_data['tn'] = model.predict(X_pred)\n",
        "\n",
        "# Operación inversa para obtener los resultados correctos\n",
        "for pid, regression in regressions.items():\n",
        "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
        "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] -= regression.predict(X_pid_pred)\n",
        "\n",
        "# Agrupar por product_id y sumar las predicciones de tn\n",
        "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
        "\n",
        "# Añadir la columna de periodo\n",
        "grouped_predictions['periodo'] = '202002'\n",
        "\n",
        "# Seleccionar columnas y guardar en CSV\n",
        "output = grouped_predictions[['product_id', 'tn']]\n",
        "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
        "\n",
        "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VP6wCe6l7gD",
        "outputId": "f2eb5ed7-125c-4381-d97b-f4882499285c"
      },
      "id": "4VP6wCe6l7gD",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-78-8cd773806014>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(0, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM con **Regresion lineal**"
      ],
      "metadata": {
        "id": "4AiSoIN7M0mj"
      },
      "id": "4AiSoIN7M0mj"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = data2.copy()\n",
        "\n",
        "# Crear características adicionales (features)\n",
        "data['year'] = data['periodo'].dt.year\n",
        "data['month'] = data['periodo'].dt.month\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos\n",
        "lags = [1, 2, 3, 6, 12]\n",
        "for lag in lags:\n",
        "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Reemplazar valores faltantes con 0\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
        "train_data = data[data['periodo'] <= '2019-12-01']\n",
        "\n",
        "# Definir las características y el target\n",
        "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
        "target = 'tn'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar un modelo de regresión lineal para cada product_id\n",
        "product_ids = data['product_id'].unique()\n",
        "regressions = {}\n",
        "coefs = {}\n",
        "for pid in product_ids:\n",
        "    X_pid = X[X['product_id'] == pid]\n",
        "    y_pid = y[X['product_id'] == pid]\n",
        "    regression = LinearRegression()\n",
        "    regression.fit(X_pid, y_pid)\n",
        "    regressions[pid] = regression\n",
        "    coefs[pid] = (regression.coef_[0], regression.intercept_)\n",
        "\n",
        "# Crear el DataFrame para las predicciones de febrero de 2020\n",
        "unique_product_ids = data2['product_id'].unique()\n",
        "unique_customer_ids = data2['customer_id'].unique()\n",
        "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
        "\n",
        "# Añadir las columnas necesarias para las características adicionales\n",
        "prediction_data['year'] = 2020\n",
        "prediction_data['month'] = 2\n",
        "\n",
        "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
        "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
        "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
        "\n",
        "# Reemplazar valores faltantes con 0\n",
        "prediction_data.fillna(0, inplace=True)\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
        "for lag in lags:\n",
        "    lag_col = f'tn_lag_{lag}'\n",
        "    prediction_data[lag_col] = 0\n",
        "    for pid in unique_product_ids:\n",
        "        mask = prediction_data['product_id'] == pid\n",
        "        if lag_col in data.columns:\n",
        "            data_lags = data.loc[data['product_id'] == pid, lag_col].values\n",
        "            pred_lags = prediction_data.loc[mask, lag_col]\n",
        "            prediction_data.loc[mask, lag_col] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags) - len(data_lags), 0), 'constant')\n",
        "\n",
        "# Predicciones usando regresión lineal para cada product_id\n",
        "for pid, regression in regressions.items():\n",
        "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
        "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] = regression.predict(X_pid_pred)\n",
        "\n",
        "# Hacer predicciones finales usando LightGBM\n",
        "model = LGBMRegressor()\n",
        "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "X_pred = prediction_data[features]\n",
        "prediction_data['transformed_tn'] = model.predict(X_pred)\n",
        "\n",
        "# Invertir la transformación para obtener los valores originales\n",
        "for pid, (coef, intercept) in coefs.items():\n",
        "    mask = prediction_data['product_id'] == pid\n",
        "    prediction_data.loc[mask, 'tn'] = prediction_data.loc[mask, 'transformed_tn'] * coef + intercept\n",
        "\n",
        "# Agrupar por product_id y sumar las predicciones de tn\n",
        "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
        "\n",
        "# Añadir la columna de periodo\n",
        "grouped_predictions['periodo'] = '202002'\n",
        "\n",
        "# Seleccionar columnas y guardar en CSV\n",
        "output = grouped_predictions[['product_id', 'tn']]\n",
        "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
        "\n",
        "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rKVkwBYJY0D",
        "outputId": "ace704fb-826e-460c-c3d5-7916d7749f4b"
      },
      "id": "0rKVkwBYJY0D",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211673 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1000\n",
            "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352071\n",
            "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LigthGBM normalizando"
      ],
      "metadata": {
        "id": "7ZqACfCnQI-j"
      },
      "id": "7ZqACfCnQI-j"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = data2.copy()\n",
        "\n",
        "# Crear características adicionales (features)\n",
        "data['year'] = data['periodo'].dt.year\n",
        "data['month'] = data['periodo'].dt.month\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos\n",
        "lags = [1, 2, 3, 6, 12]\n",
        "for lag in lags:\n",
        "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
        "\n",
        "# Reemplazar valores faltantes con 0\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
        "train_data = data[data['periodo'] <= '2019-12-01']\n",
        "\n",
        "# Definir las características y el target\n",
        "features = ['product_id','customer_id','year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
        "target = 'tn'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Normalizar características\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar un modelo de regresión lineal para cada product_id\n",
        "product_ids = data['product_id'].unique()\n",
        "regressions = {}\n",
        "coefs = {}\n",
        "for pid in product_ids:\n",
        "    X_pid = train_data[train_data['product_id'] == pid][features]\n",
        "    y_pid = train_data[train_data['product_id'] == pid][target]\n",
        "    X_pid = scaler.fit_transform(X_pid)\n",
        "    regression = LinearRegression()\n",
        "    regression.fit(X_pid, y_pid)\n",
        "    regressions[pid] = regression\n",
        "    coefs[pid] = (regression.coef_, regression.intercept_)\n",
        "\n",
        "# Crear el DataFrame para las predicciones de febrero de 2020\n",
        "unique_product_ids = data2['product_id'].unique()\n",
        "unique_customer_ids = data2['customer_id'].unique()\n",
        "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
        "\n",
        "# Añadir las columnas necesarias para las características adicionales\n",
        "prediction_data['year'] = 2020\n",
        "prediction_data['month'] = 2\n",
        "\n",
        "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
        "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
        "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
        "\n",
        "# Reemplazar valores faltantes con 0\n",
        "prediction_data.fillna(0, inplace=True)\n",
        "\n",
        "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
        "for lag in lags:\n",
        "    lag_col = f'tn_lag_{lag}'\n",
        "    prediction_data[lag_col] = 0\n",
        "    for pid in unique_product_ids:\n",
        "        mask = prediction_data['product_id'] == pid\n",
        "        if lag_col in data.columns:\n",
        "            data_lags = data.loc[data['product_id'] == pid, lag_col].values\n",
        "            pred_lags = prediction_data.loc[mask, lag_col]\n",
        "            prediction_data.loc[mask, lag_col] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags) - len(data_lags), 0), 'constant')\n",
        "\n",
        "# Predicciones usando regresión lineal para cada product_id\n",
        "for pid, regression in regressions.items():\n",
        "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
        "    X_pid_pred = scaler.transform(X_pid_pred)\n",
        "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] = regression.predict(X_pid_pred)\n",
        "\n",
        "# Ajustar los hiperparámetros del modelo LightGBM\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50],\n",
        "    'min_data_in_leaf': [20, 50, 100],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 200, 500]\n",
        "}\n",
        "lgb_model = LGBMRegressor()\n",
        "grid = GridSearchCV(lgb_model, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones finales usando el mejor modelo LightGBM\n",
        "best_model = grid.best_estimator_\n",
        "X_pred = scaler.transform(prediction_data[features])\n",
        "prediction_data['transformed_tn'] = best_model.predict(X_pred)\n",
        "\n",
        "# Invertir la transformación para obtener los valores originales\n",
        "for pid, (coef, intercept) in coefs.items():\n",
        "    mask = prediction_data['product_id'] == pid\n",
        "    prediction_data.loc[mask, 'tn'] = prediction_data.loc[mask, 'transformed_tn'] * coef[0] + intercept\n",
        "\n",
        "# Agrupar por product_id y sumar las predicciones de tn\n",
        "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
        "\n",
        "# Añadir la columna de periodo\n",
        "grouped_predictions['periodo'] = '202002'\n",
        "\n",
        "# Seleccionar columnas y guardar en CSV\n",
        "output = grouped_predictions[['product_id', 'tn']]\n",
        "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
        "\n",
        "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9qZCbheQHeY",
        "outputId": "796d9d25-ab15-4eb0-a002-9cbc4040eb3c"
      },
      "id": "t9qZCbheQHeY",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147846 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081775 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122955 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085341 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096011 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090701 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128198 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084672 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142960 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086395 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085627 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133335 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082047 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089755 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123904 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082079 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085278 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127476 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090050 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083934 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088163 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085582 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224203 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153670 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083049 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105211 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083668 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130013 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083991 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085225 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128426 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083877 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084694 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125561 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081929 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083315 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140007 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136865 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085178 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092045 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082497 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085830 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216773 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086893 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124643 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125334 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228124 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084174 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085583 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082790 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084218 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127983 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218013 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112841 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083068 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082613 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110416 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091782 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147828 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093812 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082549 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194647 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157583 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085921 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162382 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145038 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084886 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128766 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083445 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149595 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208382 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087073 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227473 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095818 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131470 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082936 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140853 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084762 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083369 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084067 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086003 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.241684 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085618 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125835 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082348 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083502 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088069 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085656 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081510 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087789 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082388 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217880 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082845 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083442 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087535 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124352 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081317 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082803 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131264 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084188 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088267 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083656 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123750 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082142 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082407 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139606 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085026 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082218 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084532 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087307 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125637 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096980 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084193 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083377 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125401 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147853 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111556 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145243 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082426 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130716 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159322 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136630 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143740 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1030\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352096\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085223 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1023\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.350355\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083698 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1014\n",
            "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.353763\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123287 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1006\n",
            "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 0.352071\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}