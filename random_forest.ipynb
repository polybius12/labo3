{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d620621-bd1e-4067-91a2-0c2626fa8a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67a3c49-067b-4e82-b93c-33f4bf27ec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_merge_data(df_ventas, df_detail):\n",
    "    df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')\n",
    "    df_ventas.sort_values(by='periodo', inplace=True)\n",
    "    print(df_ventas.shape)\n",
    "    df_ventas.drop_duplicates(inplace=True)\n",
    "    print(df_ventas.shape)\n",
    "    print(df_detail.shape)\n",
    "    df_detail.drop_duplicates(inplace=True)\n",
    "    print(df_detail.shape)\n",
    "    df_detail = df_detail[df_detail['product_id'] != 20230]\n",
    "    df_detail = df_detail[df_detail['product_id'] != 20623]\n",
    "    df = pd.merge(df_ventas, df_detail, how='left', on='product_id')\n",
    "    assert df.shape[0] - df_ventas.shape[0] == 0, 'hay duplicados'\n",
    "    \n",
    "    columns_to_uppercase = ['cat1', 'cat2', 'cat3']\n",
    "    df[columns_to_uppercase] = df[columns_to_uppercase].apply(lambda x: x.astype(str).str.upper())\n",
    "    return df\n",
    "\n",
    "def add_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['periodo'] = pd.to_datetime(df['periodo'])\n",
    "    df['month'] = df['periodo'].dt.month\n",
    "    df['year'] = df['periodo'].dt.year\n",
    "    df['day_of_week'] = df['periodo'].dt.dayofweek\n",
    "    df['day_of_month'] = df['periodo'].dt.day\n",
    "    df['week_of_year'] = df['periodo'].dt.isocalendar().week.astype(int)\n",
    "    df['quarter'] = df['periodo'].dt.quarter\n",
    "    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['sin_day_of_week'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['cos_day_of_week'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, num_lags, column_name):\n",
    "    df = df.copy()\n",
    "    for i in range(1, num_lags + 1):\n",
    "        df[f'{column_name}_lag{i}'] = df[column_name].shift(i)\n",
    "        df[f'{column_name}_diff_lag{i}'] = df[column_name].diff(i)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, windows, column_name):\n",
    "    df = df.copy()\n",
    "    for window in windows:\n",
    "        df[f'{column_name}_roll_mean_{window}'] = df[column_name].rolling(window=window).mean()\n",
    "        df[f'{column_name}_roll_std_{window}'] = df[column_name].rolling(window=window).std()\n",
    "        df[f'{column_name}_expanding_mean'] = df[column_name].expanding().mean()\n",
    "        df[f'{column_name}_expanding_std'] = df[column_name].expanding().std()\n",
    "    return df\n",
    "\n",
    "def scale_data(df_x):\n",
    "    df = df_x.copy()\n",
    "    features_to_scale = df.select_dtypes(include=[np.number]).columns.difference(['tn'])\n",
    "    scaler = StandardScaler()\n",
    "    df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "    return df\n",
    "\n",
    "def split_shift(df_x):\n",
    "    df = df_x.copy()\n",
    "    df['tn'] = df['tn'].shift(-2)    \n",
    "    train_set = df[~df['tn'].isna()]\n",
    "    predict_set = df[df['tn'].isna()]\n",
    "    return train_set, predict_set\n",
    "\n",
    "def pipeline(df_x):\n",
    "    df = df_x.copy()\n",
    "    df = df.drop(['cat1','cat2','cat3','brand'], axis=1)\n",
    "    df = create_lag_features(df, 12, 'tn')\n",
    "    df = create_rolling_features(df, [3, 6, 12], 'tn')\n",
    "    df = create_lag_features(df, 12, 'cust_request_qty')\n",
    "    df = create_rolling_features(df, [3, 6, 12], 'cust_request_qty')\n",
    "    df = df.drop(columns=['periodo'])\n",
    "    df = df.fillna(0) ## ver estrategia aca\n",
    "    df = scale_data(df)           \n",
    "    return df\n",
    "\n",
    "def predict_random_forest(df):\n",
    "    fix_cust = df.copy()\n",
    "    fix_cust = pipeline(fix_cust)   \n",
    "    train_df, predict_df = split_shift(fix_cust)\n",
    "    \n",
    "    X = train_df.drop(columns=['tn'])\n",
    "    y = train_df['tn']\n",
    "    model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    predict_df = predict_df.drop(columns=['tn'])\n",
    "    return model.predict(predict_df.tail(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db395065-939d-4177-a75d-babf9c692e8d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825ef1d6-dee2-48d7-a8ad-8f774a34371f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_data = '../labo3/data/'\n",
    "df_ventas = pd.read_csv(path_data+'sell-in.txt', delimiter='\\t', decimal='.') \n",
    "df_detail = pd.read_csv(path_data+'tb_productos.txt', delimiter='\\t')  \n",
    "df_product_to_predict = pd.read_csv(path_data+'productos_a_predecir.txt', delimiter='\\t') \n",
    "df_stocks = pd.read_csv(path_data+'tb_stocks.txt', delimiter='\\t') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4ee7c-0fd1-4733-bf22-c51af44cbd4d",
   "metadata": {},
   "source": [
    "## Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c76965b-75d5-4448-8638-9b7be9a820fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2945818, 7)\n",
      "(2945818, 7)\n",
      "(1262, 6)\n",
      "(1253, 6)\n"
     ]
    }
   ],
   "source": [
    "df = format_merge_data(df_ventas, df_detail)\n",
    "df = df[df['product_id'].isin(df_product_to_predict['product_id'].to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f8730-5766-4005-8c8b-938a1850c1e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6ba1f41-43ad-4cf3-8afd-3665764c1db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df357d74-0932-45a7-b99a-0d8f41eed415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_dict = {}\n",
    "\n",
    "# for prod_id in df['product_id'].unique():\n",
    "#     temp_list = []    \n",
    "#     for cust_id in tqdm(df['customer_id'].unique()):        \n",
    "#         fix_cust = df[(df['customer_id'] == cust_id) & (df['product_id'] == prod_id)]\n",
    "#         fix_cust = fix_cust.drop(columns=['customer_id','product_id'])        \n",
    "#         if fix_cust.shape[0] == 0:\n",
    "#             temp_list.append(0)\n",
    "#         elif fix_cust.shape[0] < 6:\n",
    "#             temp_list.append(fix_cust['tn'].mean())\n",
    "#         else:            \n",
    "#             temp_list.append(predict_random_forest(fix_cust))            \n",
    "#         final_dict[prod_id] = sum(temp_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c7963-4c92-4794-8829-5d2c90199c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def process_product_ids(chunk):\n",
    "    local_dict = {}\n",
    "    for prod_id in chunk:\n",
    "        temp_list = []\n",
    "        for cust_id in df['customer_id'].unique():\n",
    "            fix_cust = df[(df['customer_id'] == cust_id) & (df['product_id'] == prod_id)]\n",
    "            fix_cust = fix_cust.drop(columns=['customer_id', 'product_id'])\n",
    "            if fix_cust.shape[0] == 0:\n",
    "                temp_list.append(0)\n",
    "            elif fix_cust.shape[0] < 6:\n",
    "                temp_list.append(fix_cust['tn'].mean())\n",
    "            else:\n",
    "                temp_list.append(predict_random_forest(fix_cust))\n",
    "        local_dict[prod_id] = sum(temp_list)\n",
    "    return local_dict\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def main(df):\n",
    "    product_ids = df['product_id'].unique()\n",
    "    product_chunks = list(chunks(product_ids, 10))  # Change 10 to another number if you want different chunk sizes\n",
    "\n",
    "    final_dict = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_product_ids, chunk) for chunk in product_chunks]\n",
    "        for future in as_completed(futures):\n",
    "            final_dict.update(future.result())\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "# Assuming you have a DataFrame 'df' already loaded\n",
    "final_results = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bab283-b7d2-499a-a7ec-af5a229b3747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
